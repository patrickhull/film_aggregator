{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manipulate text\n",
    "def remove_paren(text):\n",
    "    table = str.maketrans(dict.fromkeys(\"()\"))\n",
    "    text = text.translate(table)\n",
    "    return text\n",
    "def na_fill(code):\n",
    "    try:\n",
    "        value = code\n",
    "    finally:\n",
    "        value = 'na'\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tables\n",
    "film_urls = []\n",
    "rank = []\n",
    "title = []\n",
    "year = []\n",
    "rating = []\n",
    "length = []\n",
    "genre = []\n",
    "date = []\n",
    "summary = []\n",
    "runtime = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = ['top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Films on each chart\n",
    "for chart in charts:\n",
    "    baseurl = 'https://www.imdb.com/chart/'\n",
    "    html = urlopen(baseurl + chart)\n",
    "    bsObj = BeautifulSoup(html)\n",
    "    film_links =  bsObj.find('div', {'class':'lister'}).table.findAll('a')\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for link in film_links:\n",
    "        ind_baseurl = 'https://www.imdb.com'\n",
    "        link = link.attrs['href']\n",
    "        url_path = ind_baseurl + link\n",
    "        if not url_path in film_urls:\n",
    "            counter = counter + 1\n",
    "            rank.append(counter)\n",
    "            film_urls.append(url_path)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-94dc11fea152>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtitle_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'\\xa0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0myear_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_paren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mrating_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenre_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'subtext'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0msummary_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'summary_text'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mruntime_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "# Individual Scraper\n",
    "for url in film_urls:\n",
    "    html = urlopen(url)\n",
    "    bsObj = BeautifulSoup(html, 'html5lib')\n",
    "    \n",
    "    title_ind = na_fill(bsObj.h1.find(text=True).replace(u'\\xa0',' ').strip())\n",
    "    year_ind = na_fill(remove_paren(bsObj.h1.span.text))\n",
    "    rating_ind, length_ind, genre_ind, date_ind = na_fill(bsObj.find('div', {'class':'subtext'}).get_text(strip=True).split('|',3))\n",
    "    summary_ind = na_fill(bsObj.find('div', {'class':'summary_text'}).get_text(strip=True))\n",
    "    runtime_ind = na_fill(bsObj.findAll('time')[1].text.replace(' min', ''))\n",
    "    \n",
    "    title.append(title_ind)\n",
    "    year.append(year_ind)\n",
    "    rating.append(rating_ind)\n",
    "    length.append(length_ind)\n",
    "    genre.append(genre_ind)\n",
    "    date.append(date_ind)\n",
    "    summary.append(summary_ind)\n",
    "    runtime.append(runtime_ind)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
